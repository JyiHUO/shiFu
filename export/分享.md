# 目录

* 比赛概况
* 数据概况
  * 交互数据
    * 特征一览
    * 标签分析
      * 交互数据finish分布
      * 交互数据like分布
      * finish and like 交叉分析

    * 每个用户平均看多少个短视频？
    * 每个用户平均观看时长？
    * 作品平均时长？
    * ...

  * 音频数据 and 视频数据

    * 数据概况

  * 脸部数据

    - 出现人脸的视频数 vs 无人脸的视频数

  * 标题数据

    * 每个短视频的平均标题长度？
    * 词频分布
    * 去除停留词后的平均标题长度
    * 标题长度与like & finish 的关系？
* 模型与实验
  * 线上成绩
  * baseline模型
  * NFFM模型
* 总结&局限性分析

# 比赛概况

![image-20190322103357910](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322103357910.png)

该比赛分为track1（大数据量赛道：**2亿交互数据**）以及track2（小数据量赛道：**1900w交互数据**）这两个赛道。除了用户的交互数据外，还有对应的视频向量，标题向量，音频向量等。参赛者的目标是使用模型来预测**在每次的交互行为中，用户多大几率完成（finish）和点赞（like）短视频，AUC是最后的评测指标**。



​					 $$result_{auc} = 0.7 * finish_{auc} + 0.3 * like_{auc} ​$$

# 数据概况

## 交互数据

![image-20190322152733262](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322152733262.png)

用户量：≈7w

短视频量：≈360w

作者量：≈77w

短视频分布地点数：= 456

观看到该作品的来源数：≈5

短视频音乐数：≈ 8w

设备：≈7w

作品时长类型数量 ≈128

#### 交互数据finish分布

![image-20190322155516178](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322155516178.png)

结论：在交互数据中，没有看完短视频的占大多数，但是总体来看还是比较均匀的。接下来我们看看like的分布。

#### 交互数据like分布

![image-20190322155714691](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322155714691.png)

结论：like的分布跟finish的分布有很大不同，点赞短视频的人数基本是百里挑一，这其实也是符合实际情况的。接下来我们微观观察每个用户和短视频的行为特点。

#### 点赞概率 when finish or not

![image-20190324214950550](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190324214950550.png)

结论：看完视频(finish == 1)的点赞概率明显比没看完视频的点赞概率要高。

#### 看完的概率 when like or not

![image-20190324215313654](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190324215313654.png)

结论：点赞的视频中5成以上的人都是看完该短视频的。相反，没有点赞的大部分是没有看完短视频的。

###  微观观察

#### 每个用户平均看多少个短视频？

![image-20190322225009602](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322225009602.png)

结论：从分布图来看，大多数用户还是会观看不止一个视频的。去掉前5%和后5%计算平均值后，每个用户平均观看210个短视频。

#### 用户平均观看时长？

![image-20190322232225325](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322232225325.png)

结论：我的前提假设是：当用户没有finish就判断观看时长为0。最后算出来用户的平均观看时长为5s左右。

#### 作品平均时长？

![image-20190322232359862](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322232359862.png)

结论：每个短视频的时长在10s左右徘徊，平均值为11s。

#### 每个用户看完短视频的概率分布

![image-20190322155100003](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322155100003.png)

结论：可以看到每个用户完成视频的概率基本符合正太分布，也就是说：用户是否看完短视频基本上是50%的概率。

#### 是否曾经有过finish行为？

![image-20190322182456810](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322182456810.png)

结论：绝大部分用户都有完整看完整个视频的行为，符合实际情况。

#### 每个用户点赞短视频的概率分布

![image-20190322175814816](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322175814816.png)

结论：画出分布图后我们可以看到，看视频总是点赞的用户几乎没有，比较正常的都是0.01的几率用户看完视频就点赞。所以我们不妨看看一下有过like行为的用户的占比把。

#### 用户是否有过like行为

![image-20190322182309996](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322182309996.png)

结论：看来从来都不点赞的小伙伴挺多的啊。怪不得有那么多没有点过赞的视频。建议：大家多点赞啊，这样我们模型正样本的数据就更加丰富了。也许你还有疑问：这些没有过like的用户和有过like的用户，他们的行为有什么不一样呢？

##### 有过like行为 vs 没有过like行为

**两类用户看完短视频的分布对比**

![image-20190322190956130](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322190956130.png)

结论：两者的大致分布相差不大，重点不一样是上图的两个红色圈。也就是说没有过点赞行为的用户更倾向于两个极端：1.一个短视频都没看完过。2.全部短视频都看完了。这两部分的用户占总用户的8%，还是比较多的。所以有必要接着刨根问底。通过计算这两类用户观看视频数的平均值，我发现仅仅只有3 << 平均值210个。所以我怀疑这类用户是下了app后，玩了一阵子就卸载了。

##音频数据 and 视频数据

每一个视频和音频特征都是使用128维度的向量来表示的，存储方式是json

```shell
{
	{
  "item_id":4567,
  "video_feature_dim_128": [0.4343, 0.4343, 0.6656, ...]
  },
  ...
}
```



## 脸部数据

```shell
[
{'face_attrs': [], 'item_id': 48318},
{'face_attrs': [], 'item_id': 1192644},
{'face_attrs': 
    [
        {'beauty': 0.6,
         'gender': 1,
         'relative_position': [0.125, 0.3125, 0.65, 0.4797]},
         ...
    ],
 'item_id': 1329871}
]
```

说明：脸部数据主要使用json来存储，如果该短视频有人脸出现，就会出现`beauty`，`gender`，`relative_position`这三个属性，视频里面每个人脸都以以上三个特征来存储。

### 出现人脸的视频数 vs 无人脸的视频数

![image-20190323163234254](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190323163234254.png)

## 标题数据

```python
[
{'item_id': 4036886,
  'title_features': {'1': 1, '2': 1, '3': 1, '4': 1, '5': 1, '6': 1}},
 {'item_id': 2893187,
  'title_features': {'7': 1, '8': 1, '9': 1}},
  ...
]
```

说明：标题数据主要以json形式来存储，每个item_id下的标题数据都是经过脱敏乱序处理，最后只保留每个字在标题里的出现的次数。

#### 每个短视频的平均标题长度？

![image-20190323103723249](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190323103723249.png)



结论：从图中我们可以看到，绝大部分短视频的标题都是3-6个字之间，去掉标题长度一百以上的短视频后，平均每个短视频的标题长度为7个字。

#### 词频分布

![download](/Users/huojunyi/Desktop/download.png)

结论：我们可以清晰看到，异常值的词频偏离严重，也就是说：基本在每个短视频的标题上总会出现这么一些词，比如说："的"，"是"，"我"…这些词其实对分析没有什么用处，我们陈这些词为停留词，需要被去掉。

#### 去除停留词后的平均标题长度

![image-20190323144320594](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190323144320594.png)

结论：缺点高频词(前1%)的词后，我发现：短视频标题长度的平均值大大减少，为2.5个。也就是说：要描述一个短视频只2个词就已经足够了。

#### 标题长度与like & finish 的关系？

![image-20190323111642959](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190323111642959.png)

结论：标题的长度对是否finish&like影响不大，标题越长的概率上升，原因是该部分采样太少了导致结论不置信。

# 模型与实验

### 线上成绩

![image-20190324224734873](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190324224734873.png)

结论：以上是我们的模型在线上的成绩，成绩最高的模型是neural Field-aware Factorization Machine( NFFM），单模型在用户的交互行为数据上达到0.78的auc。距离第一名0.8auc差0，02个点。

### baseline 模型

本次比赛中的baseline是FM，以下是抖音提供的成绩：

![image-20190324224752552](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190324224752552.png)

FM的综合成绩是： 0.74 = 0.7 * 0.698 + 0.3 * 0.865，该成绩都远远低于其他模型，比如说：DeepFM，xDeepFM等等。

### NFFM模型

这次的模型主要使用NFFM模型，该模型的的架构图如下：

![image-20190322143631579](/Users/huojunyi/Library/Application Support/typora-user-images/image-20190322143631579.png)

该模型时2017年腾讯广告算法大赛冠军杨毅分享的模型。

**Part one（FFM）**：该模型的核心思想主要是大大增加了不同field之间的交互，其实理解起来很简单，就是特征A跟特征B交互时用embedding A1和 embedding B1，特征A跟特征C交互时用embedding A2 和 embedding C2，细心的你会发现两次交互中特征A用了embedding A1 和 embedding A2，也就是说，特征A在跟其他特征交互时都有另外一套embedding，这就是我们所说的一人千脸。

**Part two（DNN）**：在前面做完特征交互后，跟一阶的特征做拼接传到DNN网络里面做全连接操作。

# 总结 & 局限性

​	总的来说，抖音短视频推荐与理解比赛是一个**数据多模态，多目标预测的比赛**，比赛数据繁杂，包括：行为交互，视频，音频，脸部，标题数据。数据量大，最大可达亿级别的数据量级。

​	比赛中遇到的问题，由于like标签的数据只有小量的正样本，所以最后的AUC普遍都会比较高(0.92)。相反，虽然finish标签的正负样本比较均匀，但是，模型能够达到的最大AUC也不过0.73. 所以，这次比赛的关键是放在如何提高finish标签的auc上，因为这样才能在抖音提供的评测指标上：$result = 0.7 * finish_{auc} + 0.3 * like_{auc}$ 拿到更高的分数。

​	一点经验，有两个目标分别是finish 和 like，那么我们要多目标还是单目标两个模型输出呢？实验证明：单目标两个模型输出会更好，根据我们观察，由于finish标签分布均匀，在采样的时候，finish的正样本会带偏like的负样本，导致在模型训练开始的时候，like的loss震荡得很厉害。最后like标签在validation上的表现比单模型的like最好成绩要低2%。

​	局限性，由于计算资源短缺的情况下只能在赛道二上做实验，没有在赛道一(亿万级别的数据量)上参赛。